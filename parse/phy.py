'''
This is a package of functions working on the phy_data object, which is created by loading files generated by phy by providing the path to the phy files and the sample rate used to acquire the data
'''

import sys
sys.path.insert(1, r'C:\Users\llarsen\OneDrive - ugentbe\python_functions')
from vies.f_curry import movingaverage, gaussian_smooth
import os
import numpy as np
import matplotlib.pyplot as plt

class phy_data:
    def __init__(self, phy_path, srate):
        directory = phy_path
        self.times = np.load(os.path.join(directory,'spike_times.npy'))
        self.templates = np.load(os.path.join(directory,'spike_clusters.npy'))
        self.amplitudes = np.load(os.path.join(directory,'amplitudes.npy'))
        self.srate = srate
        return

    def extract_frequency_bins(self, bin_size, start, stop, **kwargs):
        '''
        Parameters
        ----------
        bin_size: bin size in seconds
        start: the point in the recording where the function starts binning in seconds
        stop: the point in the recording where the function stops binning in seconds
        **kwargs: TYPE
            - templates: by defaults, the function bins all templates in the phy files. You can also provide an integer denoting a single template or a list of templates to bin.
            - smooth_method: by default, no smoothing is performed, but 'moving_average' or 'gaussian' smoothing can be performed
            - smooth_window: if smoothing is performed, provide a smoothing window (number of bins) as an integer. Default is 5 bins.
            - smooth_sigma: if gaussian smoothing is performed, provide a sigma value, denoting the narrowness of the filter

        Returns
        -------
        spike_freq: numpy array of time bins (center of bins) in seconds
        spike_count: numpy array of spike frequency in each time bin, if several templates are selected this will be a 2D array
        template_id: a lits of templates selected
        '''
        templates = kwargs.get('templates', 'all')
        smooth_method = kwargs.get('smooth_method', 'none')
        smooth_window = kwargs.get('smooth_window', 5)
        n_bins = int((stop - start)/bin_size)
        spike_freq = np.arange(0,(stop-start), bin_size) + bin_size/2
        
        if templates == 'all':
            template_id = np.unique(self.templates)
            n_templates = len(template_id)
            spike_count = np.zeros((n_bins, n_templates))
            counter = 0            
            for n_templates in np.unique(self.templates):
                index = [i for i, x in enumerate(list(self.templates)) if x == n_templates] # gets index of all matching values in templates
                spiketimes = self.times[index]/self.srate
                spike_count[:,counter] = np.histogram(spiketimes, n_bins, (start, stop))[0]
                spike_count[:,counter] = spike_count[:,counter] / bin_size
                counter = counter + 1
                
        elif isinstance(templates, int) == True:  
            n_templates = templates
            template_id = templates
            index = [i for i, x in enumerate(list(self.templates)) if x == n_templates] # gets index of all matching values in templates
            spiketimes = self.times[index]/self.srate
            spike_count = np.histogram(spiketimes, n_bins, (start, stop))[0] 
            spike_count = spike_count / bin_size
        elif isinstance(templates, list) == True:
            #print('test')
            n_templates = len(templates)
            template_id = templates
            spike_count = np.zeros((n_bins, n_templates))
            counter = 0     
            #spiketimes = self.times/self.srate
            #print(len(spiketimes))
            for n_templates in templates:
                index = [i for i, x in enumerate(list(self.templates)) if x == n_templates] # gets index of all matching values in templates
                spiketimes = self.times[index]/self.srate
                #print(len(spiketimes))
                #print(spiketimes)
                spike_count[:,counter] = np.histogram(spiketimes, n_bins, (start, stop))[0]
                #print(spike_count[:,counter])
                spike_count[:,counter] = spike_count[:,counter] / bin_size
                counter = counter + 1            
            pass
        
        if smooth_method == 'moving_average':
            if isinstance(templates, int) == True:
                spike_count = movingaverage(spike_count,smooth_window)                
            else:
                counter = 0
                for i in range(np.shape(spike_count)[1]):
                    spike_count[:,counter] = movingaverage(spike_count[:,counter],smooth_window)
                    counter = counter + 1
        elif smooth_method == 'gaussian':
            print('works')
            smooth_sigma = kwargs.get('smooth_sigma', 2)
            if isinstance(templates, int) == True:
                spike_count = gaussian_smooth(spike_count,smooth_window, smooth_sigma)                
            else:
                counter = 0
                for i in range(np.shape(spike_count)[1]):
                    spike_count[:,counter] = gaussian_smooth(spike_count[:,counter],smooth_window, smooth_sigma)
                    counter = counter + 1
        elif smooth_method == 'none':
            pass
                                    
        return spike_freq, spike_count, template_id
    
    def extract_spike_trains(self, template_id):
        template = template_id
        index = [i for i, x in enumerate(list(self.templates)) if x == template] # gets index of all matching values in templates
        spiketimes = self.times[index]/self.srate
        
        return spiketimes     

    